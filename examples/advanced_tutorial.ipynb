{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5eee2d2-7aa5-4627-b899-61b0fa05f5c9",
   "metadata": {},
   "source": [
    "# 1. Custom Encoder and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aac8e3-000d-4ffb-900f-f9dbb35bc2f9",
   "metadata": {},
   "source": [
    "First, import `CE_Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b14e56-c6bd-468d-9627-ab0a88ff9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from Custom_Encoder import CE_Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c29b3b5-0e1f-449b-a65c-3d950bbc934f",
   "metadata": {},
   "source": [
    "Define an encoder method.  \n",
    "The following is a sample implementation, but you can use any encoding approach you prefer.\n",
    "> [!NOTE]  \n",
    "> The function `get_encoder_dim()` must be implemented.\n",
    "> It should take the input feature dimension and simply return the output embedding dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c390174-910f-4071-868d-7c0665536376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class standard_code(nn.Module):\n",
    "\n",
    "  def __init__(self , input_x ) -> None:\n",
    "    super().__init__()\n",
    "    # calculate mean\n",
    "    self.mean = torch.mean(input_x , 0)\n",
    "    # calculate sigma\n",
    "    self.sigma = torch.std(input_x , dim=0)\n",
    "\n",
    "  def forward(self , x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    for i, sigma in enumerate(self.sigma):\n",
    "      row = x.t()[i].clone()\n",
    "      row_mean = row.clone()\n",
    "      row_sigma = row.clone()\n",
    "      row_mean[row_mean >self.mean[i]] = 1\n",
    "      row_mean[row_mean <self.mean[i]] = 0\n",
    "      row_sigma[row_sigma >self.sigma[i]+self.mean[i]] = 1\n",
    "      row_sigma[row_sigma <self.sigma[i]-self.mean[i]] = 1\n",
    "      row_sigma[row_sigma <self.sigma[i]+self.mean[i]] = 0\n",
    "      row_sigma[row_sigma >self.sigma[i]-self.mean[i]] = 0\n",
    "      encode = torch.stack((row_mean ,row_sigma) ,1)\n",
    "      if ( i == 0 ):\n",
    "        output = encode\n",
    "      else:\n",
    "        output = torch.cat( ( output , encode ), 1 )\n",
    "\n",
    "      return output\n",
    "\n",
    "  def get_encoder_dim(self , input_dim):\n",
    "    output_dim = input_dim*2\n",
    "    return output_dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a518e-afec-4352-ada3-29c90549c26f",
   "metadata": {},
   "source": [
    "Next, define your own model.  \n",
    "Just inherit from the `CE_Module` class, and call `self.forward_encoder()` whenever you need to forward the encoder.  \n",
    "`self.forward_encoder()` refers to the encoder in your architecture that you can replace freely. \n",
    "The following is a sample implementation, but you can replace it with your own model too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf554dd9-de00-44ce-a7c3-1a38e5d8bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCARF1(CE_Module):\n",
    "    def __init__(\n",
    "        self ,\n",
    "        input_dim ,\n",
    "        emb_dim ,\n",
    "        features_low ,\n",
    "        features_high ,\n",
    "        num_hidden=4,\n",
    "        head_depth=2,\n",
    "        corruption_rate =0.6,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = MLP(input_dim , emb_dim , num_hidden , dropout)\n",
    "        self.pretraining_head = MLP(emb_dim , emb_dim , head_depth)\n",
    "\n",
    "        # uniform distribution over marginal distributions of dataset 's features\n",
    "        self.marginals = Uniform(torch.Tensor(features_low), torch.Tensor(features_high))\n",
    "        self.corruption_len = int(corruption_rate *input_dim)\n",
    "\n",
    "    def forward(self , x):\n",
    "        batch_size , m = x.size()\n",
    "\n",
    "        corruption_mask = torch.zeros_like(x, dtype=torch.bool , device=x.device)\n",
    "        for i in range(batch_size):\n",
    "            corruption_idx = torch.randperm(m)[: self.corruption_len]\n",
    "            corruption_mask[i, corruption_idx] = True\n",
    "\n",
    "        x_random = self.marginals.sample(torch.Size((batch_size ,))).to(x.device)\n",
    "        x_corrupted = torch.where(corruption_mask , x_random, x)\n",
    "\n",
    "        # Custom Encoder\n",
    "        x = self.forward_encoder(x)\n",
    "        x_corrupted = self.forward_encoder(x_corrupted)\n",
    "\n",
    "        embeddings = self.encoder(x)\n",
    "        embeddings = self.pretraining_head(embeddings)\n",
    "\n",
    "        embeddings_corrupted = self.encoder(x_corrupted)\n",
    "        embeddings_corrupted = self.pretraining_head(embeddings_corrupted)\n",
    "\n",
    "        return embeddings , embeddings_corrupted\n",
    "\n",
    "    def adjust_structure(self):\n",
    "        self.encoder[0] = self.adjust_layer( self.encoder[0] )\n",
    "\n",
    "    def get_embedding(self):\n",
    "        return self.encoder\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def get_embeddings(self , x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc993517-650a-4555-99a9-c36e4f72f15f",
   "metadata": {},
   "source": [
    "> [!NOTE]  \n",
    "> Here are some important points to note:  \n",
    "> The function `adjust_structure()` must be implemented.  \n",
    "> Since various encoder methods need to be connected without modifying the overall model, you have to implement this function.  \n",
    ">  The `CE_Module` will automatically adjust the dimensions of the connecting layers for you.  \n",
    ">  \n",
    "> You need to provide the first `nn.Linear()` layer of the connecting layer.  \n",
    "> In this example, the structure connected after `self.forward_encoder()` is `self.encoder()`,  \n",
    "> so the first layer is `self.encoder[0]`.  \n",
    ">  \n",
    "> Calling `self.adjust_layer()` replaces the original first layer accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea75cea-5e17-44ca-9659-3391c82134c4",
   "metadata": {},
   "source": [
    "Finally, when you run experiments, create the model just like you normally do.  \n",
    "However, after initialization, make sure to call `set_encoder()`.  \n",
    "Pass in the encoder instance, the encoder dimension, and whether reshaping is needed.  \n",
    "In my example, `standard_code(features)` requires `features` for initialization; otherwise, you can call `standard_code()` directly without any issue.  \n",
    "This completes the model setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e53c5-54d9-4105-818f-948157bb0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scarf_model.SCARF1(\n",
    " input_dim=args.feature_dim ,\n",
    " emb_dim=args.emb_dim ,\n",
    " features_low=dataset.get_feature_marginal_low(),\n",
    " features_high=dataset.get_feature_marginal_high(),\n",
    " )\n",
    "\n",
    "model.set_encoder(callback=standard_code(features), encoder_dim =2*args.feature_dim , reshape=True )\n",
    "model.to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
